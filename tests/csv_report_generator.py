#!/usr/bin/env python3
"""
G√©n√©rateur de rapports CSV pour les tests JDR 4 MJ
"""

import csv
import json
import os
import sys
import subprocess
import re
from datetime import datetime
from pathlib import Path
from typing import List, Dict, Any, Optional

class CSVReportGenerator:
    """G√©n√©rateur de rapports CSV pour les tests"""
    
    def __init__(self, output_dir: str = "reports"):
        """Initialise le g√©n√©rateur de rapports"""
        self.output_dir = Path(output_dir)
        self.output_dir.mkdir(exist_ok=True)
        self.timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
        
    def parse_pytest_output(self, output: str) -> List[Dict[str, Any]]:
        """Parse la sortie de pytest pour extraire les informations des tests"""
        tests = []
        lines = output.split('\n')
        
        current_test = None
        in_failure_section = False
        
        for line in lines:
            line = line.strip()
            
            # D√©tection du d√©but d'un test
            if line.startswith('tests/') and ('::' in line or '.py::' in line):
                # Format: tests/functional/test_file.py::test_function PASSED
                # ou: tests/functional/test_file.py::TestClass::test_method FAILED
                parts = line.split()
                if len(parts) >= 2:
                    test_path = parts[0]
                    status = parts[1]
                    
                    # Extraire le nom du test
                    if '::' in test_path:
                        file_path, test_name = test_path.split('::', 1)
                    else:
                        file_path = test_path
                        test_name = "unknown"
                    
                    current_test = {
                        'file_path': file_path,
                        'test_name': test_name,
                        'status': status,
                        'error_line': '',
                        'error_message': '',
                        'duration': '',
                        'timestamp': datetime.now().isoformat()
                    }
                    tests.append(current_test)
                    in_failure_section = False
            
            # D√©tection de la dur√©e
            elif current_test and line.startswith('[') and ']' in line:
                # Format: [0.12s] ou [ 12.34s]
                duration_match = re.search(r'\[([\d.]+\s*s?)\]', line)
                if duration_match:
                    current_test['duration'] = duration_match.group(1)
            
            # D√©tection des erreurs et √©checs
            elif current_test and (line.startswith('FAILED') or line.startswith('ERROR')):
                in_failure_section = True
                current_test['status'] = 'FAILED'
            
            # Capture des messages d'erreur
            elif current_test and in_failure_section:
                if line.startswith('E   ') or line.startswith('FAILED'):
                    # Ligne d'erreur
                    error_line = line.replace('E   ', '').replace('FAILED ', '')
                    if not current_test['error_message']:
                        current_test['error_message'] = error_line
                    else:
                        current_test['error_message'] += f" | {error_line}"
                
                # Recherche de num√©ros de ligne dans les erreurs
                line_match = re.search(r'line (\d+)', line)
                if line_match and not current_test['error_line']:
                    current_test['error_line'] = line_match.group(1)
        
        return tests
    
    def run_pytest_with_json(self, test_path: str = ".", extra_args: List[str] = None) -> List[Dict[str, Any]]:
        """Ex√©cute pytest avec sortie JSON pour une meilleure capture"""
        if extra_args is None:
            extra_args = []
        
        # Commande pytest avec sortie JSON
        cmd = [
            "python3", "-m", "pytest",
            test_path,
            "--tb=short",  # Traceback court
            "-v",  # Mode verbeux
            "--durations=10",  # Afficher les 10 tests les plus lents
        ] + extra_args
        
        try:
            print(f"üîç Ex√©cution de: {' '.join(cmd)}")
            result = subprocess.run(cmd, capture_output=True, text=True, cwd=Path(__file__).parent)
            
            # Parser la sortie standard
            tests = self.parse_pytest_output(result.stdout)
            
            # Ajouter les informations d'erreur de stderr
            if result.stderr:
                stderr_lines = result.stderr.split('\n')
                for test in tests:
                    if test['status'] == 'FAILED' and not test['error_message']:
                        # Chercher des erreurs dans stderr
                        for line in stderr_lines:
                            if 'FAILED' in line or 'ERROR' in line:
                                test['error_message'] = line.strip()
                                break
            
            return tests
            
        except Exception as e:
            print(f"‚ùå Erreur lors de l'ex√©cution de pytest: {e}")
            return []
    
    def generate_csv_report(self, tests: List[Dict[str, Any]], filename: str = None) -> str:
        """G√©n√®re un rapport CSV √† partir des r√©sultats de tests"""
        if filename is None:
            filename = f"test_report_{self.timestamp}.csv"
        
        csv_path = self.output_dir / filename
        
        # En-t√™tes CSV
        headers = [
            'Timestamp',
            'Fichier_Test',
            'Nom_Test',
            'Statut',
            'Duree',
            'Ligne_Erreur',
            'Message_Erreur',
            'Categorie',
            'Priorite'
        ]
        
        try:
            with open(csv_path, 'w', newline='', encoding='utf-8') as csvfile:
                writer = csv.DictWriter(csvfile, fieldnames=headers, delimiter=';')
                writer.writeheader()
                
                for test in tests:
                    # D√©terminer la cat√©gorie bas√©e sur le chemin du fichier
                    category = self._determine_category(test['file_path'])
                    
                    # D√©terminer la priorit√© bas√©e sur le statut
                    priority = self._determine_priority(test['status'], test['error_message'])
                    
                    row = {
                        'Timestamp': test.get('timestamp', ''),
                        'Fichier_Test': test.get('file_path', ''),
                        'Nom_Test': test.get('test_name', ''),
                        'Statut': test.get('status', ''),
                        'Duree': test.get('duration', ''),
                        'Ligne_Erreur': test.get('error_line', ''),
                        'Message_Erreur': test.get('error_message', ''),
                        'Categorie': category,
                        'Priorite': priority
                    }
                    writer.writerow(row)
            
            print(f"üìä Rapport CSV g√©n√©r√©: {csv_path}")
            return str(csv_path)
            
        except Exception as e:
            print(f"‚ùå Erreur lors de la g√©n√©ration du rapport CSV: {e}")
            return ""
    
    def _determine_category(self, file_path: str) -> str:
        """D√©termine la cat√©gorie du test bas√©e sur le chemin du fichier"""
        if 'authentication' in file_path:
            return 'Authentification'
        elif 'character' in file_path:
            return 'Gestion_Personnages'
        elif 'campaign' in file_path:
            return 'Gestion_Campagnes'
        elif 'bestiary' in file_path:
            return 'Bestiaire'
        elif 'dm_user' in file_path:
            return 'Utilisateurs_MJ'
        elif 'integration' in file_path:
            return 'Integration'
        elif 'smoke' in file_path or 'smoke' in file_path:
            return 'Tests_Fumee'
        else:
            return 'Autres'
    
    def _determine_priority(self, status: str, error_message: str) -> str:
        """D√©termine la priorit√© bas√©e sur le statut et le message d'erreur"""
        if status == 'FAILED':
            if 'timeout' in error_message.lower():
                return 'Haute'
            elif 'selenium' in error_message.lower():
                return 'Moyenne'
            elif 'database' in error_message.lower():
                return 'Haute'
            else:
                return 'Moyenne'
        elif status == 'PASSED':
            return 'Basse'
        else:
            return 'Inconnue'
    
    def generate_summary_report(self, tests: List[Dict[str, Any]]) -> Dict[str, Any]:
        """G√©n√®re un r√©sum√© des r√©sultats de tests"""
        total_tests = len(tests)
        passed_tests = len([t for t in tests if t['status'] == 'PASSED'])
        failed_tests = len([t for t in tests if t['status'] == 'FAILED'])
        error_tests = len([t for t in tests if t['status'] == 'ERROR'])
        
        # Statistiques par cat√©gorie
        categories = {}
        for test in tests:
            category = self._determine_category(test['file_path'])
            if category not in categories:
                categories[category] = {'total': 0, 'passed': 0, 'failed': 0, 'error': 0}
            
            categories[category]['total'] += 1
            if test['status'] == 'PASSED':
                categories[category]['passed'] += 1
            elif test['status'] == 'FAILED':
                categories[category]['failed'] += 1
            elif test['status'] == 'ERROR':
                categories[category]['error'] += 1
        
        return {
            'timestamp': datetime.now().isoformat(),
            'total_tests': total_tests,
            'passed_tests': passed_tests,
            'failed_tests': failed_tests,
            'error_tests': error_tests,
            'success_rate': (passed_tests / total_tests * 100) if total_tests > 0 else 0,
            'categories': categories
        }
    
    def save_summary_json(self, summary: Dict[str, Any], filename: str = None) -> str:
        """Sauvegarde le r√©sum√© en format JSON"""
        if filename is None:
            filename = f"test_summary_{self.timestamp}.json"
        
        json_path = self.output_dir / filename
        
        try:
            with open(json_path, 'w', encoding='utf-8') as jsonfile:
                json.dump(summary, jsonfile, indent=2, ensure_ascii=False)
            
            print(f"üìã R√©sum√© JSON g√©n√©r√©: {json_path}")
            return str(json_path)
            
        except Exception as e:
            print(f"‚ùå Erreur lors de la g√©n√©ration du r√©sum√© JSON: {e}")
            return ""

def main():
    """Fonction principale pour tester le g√©n√©rateur"""
    import argparse
    
    parser = argparse.ArgumentParser(description='G√©n√©rateur de rapports CSV pour les tests')
    parser.add_argument('--test-path', default='functional/', 
                       help='Chemin vers les tests √† ex√©cuter')
    parser.add_argument('--output-dir', default='reports',
                       help='R√©pertoire de sortie pour les rapports')
    parser.add_argument('--extra-args', nargs='*', default=[],
                       help='Arguments suppl√©mentaires pour pytest')
    
    args = parser.parse_args()
    
    print("üé≤ G√©n√©rateur de Rapports CSV - JDR 4 MJ")
    print("=" * 50)
    
    # Cr√©er le g√©n√©rateur
    generator = CSVReportGenerator(args.output_dir)
    
    # Ex√©cuter les tests et capturer les r√©sultats
    print(f"üß™ Ex√©cution des tests dans: {args.test_path}")
    tests = generator.run_pytest_with_json(args.test_path, args.extra_args)
    
    if not tests:
        print("‚ùå Aucun test trouv√© ou erreur lors de l'ex√©cution")
        return 1
    
    print(f"üìä {len(tests)} tests trouv√©s")
    
    # G√©n√©rer le rapport CSV
    csv_file = generator.generate_csv_report(tests)
    
    # G√©n√©rer le r√©sum√©
    summary = generator.generate_summary_report(tests)
    json_file = generator.save_summary_json(summary)
    
    # Afficher le r√©sum√©
    print("\nüìã R√âSUM√â DES TESTS")
    print("=" * 30)
    print(f"Total des tests: {summary['total_tests']}")
    print(f"Tests r√©ussis: {summary['passed_tests']}")
    print(f"Tests √©chou√©s: {summary['failed_tests']}")
    print(f"Tests en erreur: {summary['error_tests']}")
    print(f"Taux de r√©ussite: {summary['success_rate']:.1f}%")
    
    print(f"\nüìÅ Fichiers g√©n√©r√©s:")
    print(f"  - Rapport CSV: {csv_file}")
    print(f"  - R√©sum√© JSON: {json_file}")
    
    return 0

if __name__ == '__main__':
    sys.exit(main())
