#!/usr/bin/env python3
"""
Plugin pytest pour la g√©n√©ration automatique de rapports JSON
"""

import pytest
import time
import sys
import os
from pathlib import Path

# Ajouter le r√©pertoire tests au path pour importer json_test_reporter
sys.path.insert(0, str(Path(__file__).parent))

try:
    from json_test_reporter import JSONTestReporter
    JSON_REPORTER_AVAILABLE = True
except ImportError:
    JSON_REPORTER_AVAILABLE = False

class JSONReporterPlugin:
    """Plugin pytest pour g√©n√©rer des rapports JSON automatiquement"""
    
    def __init__(self):
        self.reporter = None
        self._skipped_tests = set()  # Pour tracker les tests ignor√©s d√©j√† trait√©s
        
        if JSON_REPORTER_AVAILABLE:
            # R√©cup√©rer l'URL de base depuis les variables d'environnement
            base_url = os.getenv("TEST_BASE_URL", "http://localhost/jdrmj")
            self.reporter = JSONTestReporter(base_url=base_url)
    
    def pytest_sessionstart(self, session):
        """D√©but de session de tests"""
        print("üé≤ D√©but de session de tests avec rapports JSON individuels")
    
    def pytest_sessionfinish(self, session, exitstatus):
        """Fin de session de tests"""
        print("üìä Session de tests termin√©e - rapports individuels g√©n√©r√©s")
    
    def pytest_runtest_setup(self, item):
        """Avant l'ex√©cution d'un test"""
        if self.reporter:
            item.start_time = time.time()
    
    def pytest_runtest_teardown(self, item, nextitem):
        """Apr√®s l'ex√©cution d'un test"""
        print(f"DEBUG: teardown appel√© pour {item.name}")
        if not self.reporter or not hasattr(item, 'start_time'):
            return
        
        # V√©rifier si le test a √©t√© ignor√© - si oui, ne pas cr√©er de rapport ici
        # car il a d√©j√† √©t√© cr√©√© dans pytest_runtest_logreport
        test_nodeid = f"{item.fspath}::{item.cls.__name__}::{item.name}" if hasattr(item, 'cls') and item.cls else f"{item.fspath}::{item.name}"
        if test_nodeid in self._skipped_tests:
            return
        
        end_time = time.time()
        
        # R√©cup√©rer les informations du test
        test_name = item.name
        test_file = str(item.fspath)
        
        # D√©terminer le statut du test
        status = "PASSED"  # Par d√©faut
        error_message = ""
        error_line = ""
        
        # V√©rifier le statut du test
        if hasattr(item, 'rep_call'):
            if item.rep_call.failed:
                status = "FAILED"
                if hasattr(item.rep_call, 'longrepr'):
                    error_message = str(item.rep_call.longrepr)
                    # Extraire le num√©ro de ligne si possible
                    if "line" in error_message:
                        import re
                        line_match = re.search(r'line (\d+)', error_message)
                        if line_match:
                            error_line = line_match.group(1)
        
        # Cr√©er le rapport JSON pour ce test
        report_path = self.reporter.create_test_report(
            test_name=test_name,
            test_file=test_file,
            status=status,
            start_time=item.start_time,
            end_time=end_time,
            error_message=error_message,
            error_line=error_line
        )
        
        # Rapport individuel cr√©√© - pas besoin de le stocker pour une session
    
    def pytest_runtest_logreport(self, report):
        """Log des r√©sultats de test"""
        # Debug: afficher tous les rapports (d√©sactiv√© pour les tests)
        # print(f"DEBUG: logreport - when={report.when}, outcome={report.outcome}, skipped={report.skipped}")
        
        if report.when == 'call':
            # Stocker le rapport pour l'utiliser dans teardown
            if hasattr(report, 'item'):
                report.item.rep_call = report
                
        # Traiter les tests ignor√©s (peuvent √™tre ignor√©s √† n'importe quel moment)
        if report.skipped and self.reporter:
            self._create_test_report_from_logreport(report)
            # Marquer ce test comme trait√© pour √©viter qu'il soit trait√© dans teardown
            self._skipped_tests.add(report.nodeid)
        
        # √âviter que la phase teardown cr√©e un rapport pour les tests ignor√©s
        if report.when == 'teardown' and report.nodeid in self._skipped_tests:
            return
    
    def _create_test_report_from_logreport(self, report):
        """Cr√©er un rapport JSON √† partir d'un logreport pytest"""
        # Extraire le nom du test depuis nodeid
        test_name = report.nodeid.split("::")[-1] if "::" in report.nodeid else report.nodeid
        test_file = str(report.fspath) if hasattr(report, 'fspath') else ""
        
        # D√©terminer le statut
        status = "SKIPPED"
        error_message = ""
        if hasattr(report, 'longrepr') and report.longrepr:
            error_message = str(report.longrepr)
        
        # Utiliser les timestamps du rapport si disponibles
        start_time = getattr(report, 'start', time.time() - 1)
        end_time = getattr(report, 'stop', time.time())
        
        # Cr√©er le rapport JSON
        report_path = self.reporter.create_test_report(
            test_name=test_name,
            test_file=test_file,
            status=status,
            start_time=start_time,
            end_time=end_time,
            error_message=error_message,
            error_line=""
        )
        
        # Rapport individuel cr√©√© - pas besoin de le stocker pour une session

# Instance globale du plugin
json_reporter_plugin = JSONReporterPlugin()

def pytest_configure(config):
    """Configuration pytest"""
    if JSON_REPORTER_AVAILABLE:
        config.pluginmanager.register(json_reporter_plugin, "json_reporter")
        print("‚úÖ Plugin de rapports JSON activ√©")
    else:
        print("‚ö†Ô∏è Plugin de rapports JSON non disponible (json_test_reporter.py manquant)")

def pytest_unconfigure(config):
    """Nettoyage pytest"""
    if JSON_REPORTER_AVAILABLE:
        config.pluginmanager.unregister(json_reporter_plugin)

# D√©corateur pour les tests qui veulent des rapports JSON personnalis√©s
def json_report(test_name=None, category=None, priority=None):
    """D√©corateur pour marquer un test avec des m√©tadonn√©es JSON"""
    def decorator(func):
        func._json_report_name = test_name or func.__name__
        func._json_report_category = category
        func._json_report_priority = priority
        return func
    return decorator
